# üëã Hi there! I'm Aleksandr Zhegalin (EZLOGIC)

## üß™ QA Engineer | Test Automation Specialist | AI Testing Researcher

I specialize in test automation and building reliable testing frameworks. I'm passionate about writing clean and maintainable test code.

### ü§ñ AI Testing & Research
Currently focused on AI systems testing and research, including:
- **Manual & Automated AI Testing** - developing and executing comprehensive test strategies for AI products
- **AI Testing Methodology** - researching and developing custom test methods, frameworks, and metrics for AI functionalities
- **AI Research** - investigating RAG systems, Embeddings, custom models development, and future AI evolution
- **Exploratory Testing** - discovering edge cases and potential issues in AI behavior

**Key Achievements:**
- ‚ú® Developed custom test methods for AI functionalities
- üìö Described comprehensive AI testing methodology

---

## üõ†Ô∏è Tech Stack & Tools

### Programming Languages
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)

### Test Automation Frameworks
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![Playwright](https://img.shields.io/badge/Playwright-2EAD33?style=for-the-badge&logo=playwright&logoColor=white)
![Pytest](https://img.shields.io/badge/Pytest-0A9EDC?style=for-the-badge&logo=pytest&logoColor=white)

### AI Testing & Research
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)
- RAG Systems Testing
- Embeddings & Vector Databases
- LLM Testing & Evaluation
- Custom AI Test Methodologies

### Tools
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)
![VS Code](https://img.shields.io/badge/VS_Code-007ACC?style=for-the-badge&logo=visual-studio-code&logoColor=white)

---

## üìä GitHub Stats

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=EZLOGIC&show_icons=true&theme=radical&hide_border=true)

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=EZLOGIC&layout=compact&theme=radical&hide_border=true)

---

## üéì Certificates & Education

- üèÜ [HackerRank SQL Certificate](https://www.hackerrank.com/certificates/f5c93f568ea0) - Practical SQL skills validation
- üìú [QA Manual Testing Course - Mentorpiece](https://mentorpiece.education/alumni/230406/) - Comprehensive manual testing course
- üìö [Stepik: Test Automation with Selenium and Python](https://stepik.org/cert/1892880?lang=en) - Fundamentals of test automation

---

## üìù Technical Writing & Research

I write in-depth technical articles about AI testing methodologies and metrics on Habr.com (in Russian):

**AI Testing Research Series:**
- üìä [Testing AI Models - Part 1](https://habr.com/ru/articles/930378/) - Manual and automated testing of 18 AI models using custom criteria (relevance, completeness, clarity, speed, brevity)
- üìà [Testing AI Models - Part 2](https://habr.com/ru/articles/932266/) - Deep dive into evaluation metrics: Precision, Recall, Specificity, Confusion Matrix, MAP, MRR with Python implementations
- üî¨ [Testing AI Models - Part 3](https://habr.com/ru/articles/935408/) - Comprehensive guide to AI evaluation metrics including F-Beta Score, BLEU, ROUGE, BERTScore, InfoLM, CER, ChrF, TER, WER, Cross-Entropy, and custom SACEL metric
- üéØ [Testing AI Models - Part 4](https://habr.com/ru/articles/951222/) - RAG evaluation metrics and advanced AI testing techniques
- üöÄ **Coming Soon:** Complete DeepEval Framework Guide - Comprehensive overview of 32+ metrics covering:
  - **Agentic Metrics**: Task Completion, Tool Correctness, Argument Correctness
  - **Multi-Turn Metrics**: Turn Relevancy, Role Adherence, Knowledge Retention, Conversation Completeness
  - **MCP Metrics**: MCP-Use, Multi-Turn MCP-Use, MCP Task Completion
  - **Safety Metrics**: Bias, Toxicity, Non-Advice, Misuse, PII Leakage, Role Violation
  - **General Metrics**: Summarization, Prompt Alignment, Hallucination, JSON Correctness
  - **Multimodal Metrics**: Image Coherence, Image Helpfulness, Text-to-Image, Image Editing, and more
  - Practical implementations using **Checkpointer** and **LangSmith**

**Key Topics:**
- Custom AI testing methodologies development
- Evaluation metrics analysis and implementation
- AI Agents and MCP (Model Context Protocol) testing
- Safety and ethical AI evaluation
- Multimodal AI systems testing
- Python code examples for each metric
- Practical applications in real projects

---

## üì´ Get in Touch

[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/EZlogic)
[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white)](https://discord.com/users/esylogic_66970)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:esylogic@gmail.com)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/aleksandr-zhegalin-93512327a/)

---

‚≠êÔ∏è Open to collaboration and knowledge sharing!
